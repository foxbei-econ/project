{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_title_short                                          job_title  \\\n",
       "0  Senior Data Engineer  Senior Clinical Data Engineer / Principal Clin...   \n",
       "1          Data Analyst                                       Data Analyst   \n",
       "2         Data Engineer  Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "\n",
       "                   job_location           job_via job_schedule_type  \\\n",
       "0                 Watertown, CT   via Work Nearby         Full-time   \n",
       "1  Guadalajara, Jalisco, Mexico  via BeBee México         Full-time   \n",
       "2               Berlin, Germany      via LinkedIn         Full-time   \n",
       "\n",
       "   job_work_from_home       search_location     job_posted_date  \\\n",
       "0               False  Texas, United States 2023-06-16 13:44:15   \n",
       "1               False                Mexico 2023-01-14 13:18:07   \n",
       "2               False               Germany 2023-10-10 13:14:55   \n",
       "\n",
       "   job_no_degree_mention  job_health_insurance    job_country salary_rate  \\\n",
       "0                  False                 False  United States        None   \n",
       "1                  False                 False         Mexico        None   \n",
       "2                  False                 False        Germany        None   \n",
       "\n",
       "   salary_year_avg  salary_hour_avg                company_name  \\\n",
       "0              NaN              NaN        Boehringer Ingelheim   \n",
       "1              NaN              NaN  Hewlett Packard Enterprise   \n",
       "2              NaN              NaN    ALPHA Augmented Services   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0                                               None   \n",
       "1  ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2  ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "\n",
       "                                     job_type_skills  \n",
       "0                                               None  \n",
       "1  {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2  {'analyst_tools': ['dax'], 'cloud': ['azure'],...  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset['train'].to_pandas()\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna(subset = ['salary_year_avg'])\n",
    "print(f'the original df rows are {len(df)}')\n",
    "print(f'the filtered df rows are {len(df_cleaned)}')\n",
    "print(f'the rows removed are {len(df)-len(df_cleaned)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.drop_duplicates(subset = ['job_location'])\n",
    "print(f'the original # of rows are {len(df)}')\n",
    "print(f'the cleaned # of rows are {len(df_cleaned)}')\n",
    "print(f'the rows removed are {len(df)-len(df_cleaned)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_before = df['salary_rate'].head(10)\n",
    "\n",
    "df['salary_rate'] = df['salary_rate'].fillna(value = 'Unknown')\n",
    "salary_after = df['salary_rate'].head(10)\n",
    "\n",
    "salary_before, salary_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "# print(id(df_copy),id(df))\n",
    "df_copy.dropna(subset = ['salary_year_avg'],inplace=True)\n",
    "df_copy1 = df_copy.dropna(subset = ['salary_year_avg'])\n",
    "\n",
    "type(df_copy1), df_copy1.head()\n",
    "# df_copy.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frac = df.sample(frac=0.1)\n",
    "df_frac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "median = df_copy['salary_year_avg'].median()\n",
    "df_copy['salary_year_avg'] = df_copy['salary_year_avg'].fillna(value=median)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index=['job_title_short','job_country'],aggfunc='size').head(10)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[df['job_title_short']=='Data Scientist'].copy()\n",
    "df_pivot = df_new.pivot_table(values='salary_year_avg',index=['company_name','job_country'],aggfunc='median')\n",
    "\n",
    "df_pivot_filter = df_pivot[df_pivot['salary_year_avg'] > 200000]\n",
    "df_pivot_filter.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy.set_index('job_posted_date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.reset_index(drop=True,inplace=True)\n",
    "# df_copy.drop(labels='job_posted_date',axis=1, inplace=True)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_pivot = df_copy.pivot_table(values='salary_year_avg',index='company_name',aggfunc='median')\n",
    "df_pivot\n",
    "df_pivot.sort_index(ascending=False,inplace=True)\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_pivot = df_copy.pivot_table(values='salary_year_avg',index='job_title_short',aggfunc='median')\n",
    "df_pivot.reset_index(inplace=True)\n",
    "df_pivot\n",
    "df_pivot.set_index('salary_year_avg',inplace=True)\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skill count per month for data analysts\n",
    "df_US = df[df['job_country'] == 'United States'].copy()\n",
    "\n",
    "# extract the month name from 'job_posted_date'\n",
    "df_US['job_posted_month'] = df_US['job_posted_date'].dt.strftime('%B')\n",
    "# df_US['job_posted_month']\n",
    "\n",
    "df_US_pivot = df_US.pivot_table(index='job_posted_month', columns='job_title_short', aggfunc='size')\n",
    "# df_US_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort job_posted_month_name in df_US_pivot by job_posted_month value\n",
    "df_US_pivot = df_US_pivot.reset_index()\n",
    "df_US_pivot['job_posted_month_no'] = pd.to_datetime(df_US_pivot['job_posted_month'], format='%B').dt.month\n",
    "df_US_pivot = df_US_pivot.sort_values('job_posted_month_no')\n",
    "df_US_pivot = df_US_pivot.set_index('job_posted_month')\n",
    "df_US_pivot = df_US_pivot.drop(columns='job_posted_month_no')\n",
    "\n",
    "df_US_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst', 'Data Scientist', 'Data Engineer']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3 = df_US['job_title_short'].value_counts().head(3)\n",
    "top_3 = top_3.index.tolist()\n",
    "top_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_us_jobs = df[df['job_country']=='United States'].copy()\n",
    "df_us_jobs['job_posted_month'] = df_us_jobs['job_posted_date'].dt.to_period('M')\n",
    "df_monthly_postings = df_us_jobs.groupby('job_posted_month').size().reset_index(name='postings_count')\n",
    "merge_df = pd.merge(df_us_jobs,df_monthly_postings, how='right',on='job_posted_month')\n",
    "# df_us_jobs\n",
    "df_monthly_postings\n",
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_remote_jobs = df[df['job_work_from_home']==False].copy()\n",
    "# df_not_remote_jobs.head(3)\n",
    "df_not_remote_salary = df_not_remote_jobs.pivot_table(values='salary_year_avg',index='job_title_short',aggfunc='mean').reset_index()\n",
    "df_not_remote_salary.rename(columns={'salary_year_avg':'salary_not_remote_avg'},inplace=True)\n",
    "# df_not_remote_salary\n",
    "merge_df = pd.merge(df_not_remote_jobs,df_not_remote_salary,how='right',on='job_title_short')\n",
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_remote_jobs = df[df['job_work_from_home']==False].copy()\n",
    "# df_not_remote_jobs.head(3)\n",
    "df_not_remote_salary = df_not_remote_jobs.groupby('job_title_short')['salary_year_avg'].mean().reset_index()\n",
    "# df_not_remote_salary\n",
    "df_not_remote_salary.rename(columns={'salary_year_avg':'salary_not_remote_avg'},inplace=True)\n",
    "merge_df = pd.merge(df_not_remote_jobs,df_not_remote_salary,how='right',on='job_title_short')\n",
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_salary = df.groupby('company_name')['salary_year_avg'].mean().reset_index()\n",
    "# df_company_salary\n",
    "df_company_remote = df[df['job_work_from_home']==True].groupby('company_name').size().reset_index(name='remote_count')\n",
    "# df_company_remote\n",
    "merge_df = pd.merge(df_company_salary, df_company_remote, how='inner',on='company_name')\n",
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_posted_month'] = df['job_posted_date'].dt.strftime('%b')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = df['job_posted_month'].unique()\n",
    "print(months)\n",
    "\n",
    "# write this with dict comprehension\n",
    "dict_months = {month: df[df['job_posted_month'] == month] for month in months}\n",
    "# dict_months\n",
    "\n",
    "\n",
    "# long way\n",
    "# dict_months = {}\n",
    "# for month in months:\n",
    "#     dict_months[month] = df[df['job_posted_month'] == month]\n",
    "\n",
    "type(dict_months)\n",
    "type(dict_months['Jun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "      <th>job_posted_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_title_short, job_title, job_location, job_via, job_schedule_type, job_work_from_home, search_location, job_posted_date, job_no_degree_mention, job_health_insurance, job_country, salary_rate, salary_year_avg, salary_hour_avg, company_name, job_skills, job_type_skills, job_posted_month]\n",
       "Index: []"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
